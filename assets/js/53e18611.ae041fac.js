"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[349],{3905:function(e,t,r){r.d(t,{Zo:function(){return c},kt:function(){return d}});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function a(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var u=n.createContext({}),l=function(e){var t=n.useContext(u),r=t;return e&&(r="function"==typeof e?e(t):a(a({},t),e)),r},c=function(e){var t=l(e.components);return n.createElement(u.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,i=e.originalType,u=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),f=l(r),d=o,m=f["".concat(u,".").concat(d)]||f[d]||p[d]||i;return r?n.createElement(m,a(a({ref:t},c),{},{components:r})):n.createElement(m,a({ref:t},c))}));function d(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=r.length,a=new Array(i);a[0]=f;var s={};for(var u in t)hasOwnProperty.call(t,u)&&(s[u]=t[u]);s.originalType=e,s.mdxType="string"==typeof e?e:o,a[1]=s;for(var l=2;l<i;l++)a[l]=r[l];return n.createElement.apply(null,a)}return n.createElement.apply(null,r)}f.displayName="MDXCreateElement"},7780:function(e,t,r){r.r(t),r.d(t,{frontMatter:function(){return s},contentTitle:function(){return u},metadata:function(){return l},toc:function(){return c},default:function(){return f}});var n=r(7462),o=r(3366),i=(r(7294),r(3905)),a=["components"],s={slug:"/",sidebar_position:1},u="Introduction",l={unversionedId:"introduction",id:"introduction",title:"Introduction",description:"zio-spark provides an easy way to deal with Spark using ZIO runtime. The library is designed to be as close to the Spark API as possible. It allows us to use our favorite ZIO functionnalities in our Spark job such as:",source:"@site/../docs/introduction.md",sourceDirName:".",slug:"/",permalink:"/zio-spark/",editUrl:"https://github.com/univalence/zio-spark/edit/master/docs/../docs/introduction.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{slug:"/",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Getting started",permalink:"/zio-spark/getting-started"}},c=[{value:"About performances",id:"about-performances",children:[],level:2}],p={toc:c};function f(e){var t=e.components,r=(0,o.Z)(e,a);return(0,i.kt)("wrapper",(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,"zio-spark provides an easy way to deal with Spark using ZIO runtime. The library is designed to be as close to the Spark API as possible. It allows us to use our favorite ZIO functionnalities in our Spark job such as:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"using ZLayer to inject the SparkSession"),(0,i.kt)("li",{parentName:"ul"},"running our job in parrallel"),(0,i.kt)("li",{parentName:"ul"},"retrying our job easily"),(0,i.kt)("li",{parentName:"ul"},"increasing the performances of our jobs")),(0,i.kt)("h2",{id:"about-performances"},"About performances"),(0,i.kt)("p",null,"There are usual ways to improve the performances of spark jobs, in order of priority:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"less join"),(0,i.kt)("li",{parentName:"ul"},"less data (=> active location, streaming, ...)"),(0,i.kt)("li",{parentName:"ul"},"less udf/rdd"),(0,i.kt)("li",{parentName:"ul"},"better configuration"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"better resource allocation")," <-")),(0,i.kt)("p",null,"What zio-spark can do is to launch different spark jobs in the same ",(0,i.kt)("inlineCode",{parentName:"p"},"SparkSession"),", allowing to use more of the\nexecutors capacity. Eg. if you have 5 workers, and only 1 is working to finish the current job, and you wait before\nstarting another job, that's not what's best efficiency, and at the end not the best for the lead time."),(0,i.kt)("p",null,"On some pipeline, concurrent job launch speed up the pipeline by 2-10 times. It's not \"faster\", it's just the overall\nlead time (wall clock time) is better."),(0,i.kt)("p",null,"Spark is very good at optimizing the work on a single job, there is no issue with spark, but the imperative nature of\nthe API don't allow Spark to know for remaining jobs."))}f.isMDXComponent=!0}}]);