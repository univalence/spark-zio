"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[338],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(n),m=r,k=u["".concat(s,".").concat(m)]||u[m]||d[m]||o;return n?a.createElement(k,i(i({ref:t},c),{},{components:n})):a.createElement(k,i({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},334:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return p},toc:function(){return c},default:function(){return u}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=["components"],l={sidebar_position:2},s="Code Generation",p={unversionedId:"for-developers/code-generation",id:"for-developers/code-generation",title:"Code Generation",description:"Like we already said, the main Spark classes are auto generated in Zio-Spark. We have to add our own classes because",source:"@site/../docs/for-developers/code-generation.md",sourceDirName:"for-developers",slug:"/for-developers/code-generation",permalink:"/zio-spark/for-developers/code-generation",editUrl:"https://github.com/univalence/zio-spark/edit/master/docs/../docs/for-developers/code-generation.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Overview",permalink:"/zio-spark/for-developers/overview"},next:{title:"Overview",permalink:"/zio-spark/experimental/overview"}},c=[{value:"Example",id:"example",children:[{value:"Overlays",id:"overlays",children:[],level:3}],level:2}],d={toc:c};function u(e){var t=e.components,n=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"code-generation"},"Code Generation"),(0,o.kt)("p",null,"Like we already said, the main Spark classes are auto generated in Zio-Spark. We have to add our own classes because\nSpark is Impure and not ZIO aware."),(0,o.kt)("p",null,"A generated class is composed by three kind of codes:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The code automatically generated from Spark"),(0,o.kt)("li",{parentName:"ul"},"The scala version specific code written in Zio-Spark to add Zio-Spark functionalities"),(0,o.kt)("li",{parentName:"ul"},"The scala version non-specific code written in Zio-Spark to add Zio-Spark functionalities")),(0,o.kt)("h2",{id:"example"},"Example"),(0,o.kt)("p",null,"Generally speaking here is the workflow that auto-generate a Zio-Spark class:"),(0,o.kt)("p",null,"Let's take ",(0,o.kt)("inlineCode",{parentName:"p"},"Dataset")," as an example !"),(0,o.kt)("p",null,"Everything start with a GenerationPlan, the plan read sources from Spark and use them to generate the ",(0,o.kt)("inlineCode",{parentName:"p"},"Zio-Spark")," sources.\nWe decided to store the generated file in ",(0,o.kt)("inlineCode",{parentName:"p"},"zio-spark-core/src/main/scala-$version/zio/spark/sql/Dataset.scala")," directly.\nIt allows us to compare the differences using git and it is clearer for people to understand what's happening."),(0,o.kt)("p",null,"When SBT is compiling the ",(0,o.kt)("inlineCode",{parentName:"p"},"core")," module, based on the ",(0,o.kt)("inlineCode",{parentName:"p"},"zio-spark-codegen")," plugin :"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"We read the Spark code source of the ",(0,o.kt)("inlineCode",{parentName:"li"},"Dataset")," using SBT\n(in ",(0,o.kt)("inlineCode",{parentName:"li"},"org.apache.spark/spark-sql:org/apache/spark/sql/Dataset.scala"),")"),(0,o.kt)("li",{parentName:"ol"},"We use Scalameta to read the source, analyse, and generate the code for zio-spark",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"We group all class methods by type and wrapping them."),(0,o.kt)("li",{parentName:"ul"},"We need to specify class specific import and folks."),(0,o.kt)("li",{parentName:"ul"},"We add extra chunks of code from the overlays"))),(0,o.kt)("li",{parentName:"ol"},"We write the merged output for the target scala version (current ",(0,o.kt)("inlineCode",{parentName:"li"},"$version")," used by the core module during\ncompilation) into  ",(0,o.kt)("inlineCode",{parentName:"li"},"zio-spark-core/src/main/scala-$version/zio/spark/sql/Dataset.scala"))),(0,o.kt)("h3",{id:"overlays"},"Overlays"),(0,o.kt)("p",null,"At the beginning, the generated code contains only one kind of code: the code automatically generated from Spark."),(0,o.kt)("p",null,"You can then use this code to generate an overlays. They allow us to add our scala version specific and non-specific\nfunctions."),(0,o.kt)("p",null,"These overlays can be found in ",(0,o.kt)("inlineCode",{parentName:"p"},"zio-spark-core/src/it/scala..."),"."),(0,o.kt)("p",null,"For Dataset, you will find four overlays:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"zio-spark-core/src/it/scala/DatasetOverlay.scala")," -> The code shared by all scala versions"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"zio-spark-core/src/it/scala-$version/DatasetOverlay.scala")," -> The code specific for all scala versions")),(0,o.kt)("p",null,"For general name pattern is ",(0,o.kt)("inlineCode",{parentName:"p"},"${ClassName}Overlay")," (",(0,o.kt)("inlineCode",{parentName:"p"},"$ClassName")," in ",(0,o.kt)("inlineCode",{parentName:"p"},"Dataset"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"RDD"),", ...)"),(0,o.kt)("p",null,"If you recompile adding these overlays, the function between ",(0,o.kt)("inlineCode",{parentName:"p"},"template:on")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"template:off")," will be added to the\ngenerated code."))}u.isMDXComponent=!0}}]);