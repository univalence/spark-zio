"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[349],{3905:function(e,t,r){r.d(t,{Zo:function(){return c},kt:function(){return d}});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function a(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=n.createContext({}),u=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):a(a({},t),e)),r},c=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),f=u(r),d=o,m=f["".concat(l,".").concat(d)]||f[d]||p[d]||i;return r?n.createElement(m,a(a({ref:t},c),{},{components:r})):n.createElement(m,a({ref:t},c))}));function d(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=r.length,a=new Array(i);a[0]=f;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,a[1]=s;for(var u=2;u<i;u++)a[u]=r[u];return n.createElement.apply(null,a)}return n.createElement.apply(null,r)}f.displayName="MDXCreateElement"},7780:function(e,t,r){r.r(t),r.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return u},toc:function(){return c},default:function(){return f}});var n=r(7462),o=r(3366),i=(r(7294),r(3905)),a=["components"],s={slug:"/",sidebar_position:1},l="Introduction",u={unversionedId:"introduction",id:"introduction",title:"Introduction",description:"Zio-spark provides an easy way to deal with Spark using ZIO runtime. The library is designed to be as close to the Spark",source:"@site/../docs/introduction.md",sourceDirName:".",slug:"/",permalink:"/zio-spark/",editUrl:"https://github.com/univalence/zio-spark/edit/master/docs/../docs/introduction.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{slug:"/",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Getting started",permalink:"/zio-spark/getting-started"}},c=[{value:"About performances",id:"about-performances",children:[],level:2}],p={toc:c};function f(e){var t=e.components,r=(0,o.Z)(e,a);return(0,i.kt)("wrapper",(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,"Zio-spark provides an easy way to deal with Spark using ZIO runtime. The library is designed to be as close to the Spark\nAPI as possible. It allows us to use our favorite ZIO functionalities in our Spark job such as:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"using ZLayer to inject the SparkSession"),(0,i.kt)("li",{parentName:"ul"},"running jobs in parallel"),(0,i.kt)("li",{parentName:"ul"},"retrying jobs"),(0,i.kt)("li",{parentName:"ul"},"scheduling jobs"),(0,i.kt)("li",{parentName:"ul"},"canceling jobs"),(0,i.kt)("li",{parentName:"ul"},"increasing the performances of our jobs")),(0,i.kt)("h2",{id:"about-performances"},"About performances"),(0,i.kt)("p",null,"There are usual ways to improve the performances of spark jobs, in order of priority:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"less join"),(0,i.kt)("li",{parentName:"ul"},"less data (=> active location, streaming, ...)"),(0,i.kt)("li",{parentName:"ul"},"less udf/rdd"),(0,i.kt)("li",{parentName:"ul"},"better configuration"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"better resource allocation")," <-")),(0,i.kt)("p",null,"What zio-spark can do is to launch different spark jobs in the same ",(0,i.kt)("inlineCode",{parentName:"p"},"SparkSession"),", allowing to use more of the\nexecutor capacities. E.g. if you have 5 workers, and only 1 is working to finish the current job, and you wait before\nstarting another job, it is not the best for the lead time."),(0,i.kt)("p",null,"On some pipeline, concurrent job launch speed up the pipeline by 2-10 times. It's not \"faster\", it's just the overall\nlead time (wall clock time) is better."),(0,i.kt)("p",null,"Spark is very good at optimizing the work on a single job, there is no issue with spark, but the imperative nature of\nthe API don't allow Spark to know for remaining jobs."))}f.isMDXComponent=!0}}]);